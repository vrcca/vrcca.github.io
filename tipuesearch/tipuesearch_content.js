var tipuesearch = {"pages": [{"url": "https://blog.vitor.info/post/writing-better-tests-in-java/", "text": "Ever wondered why your tests break everytime you change production code? Are your tests difficult to read? This usually happens due to tests being too attached to the corresponding implementation. I will show a few techniques on how to writte better tests in Java. PS.: I will call \u201cProduction Code\u201d, the code that you write to make your tests pass. Changing Production Code Breaks Many Tests When your tests are too specific and bound to its implementation, you will notice that any changes to the production code such as extracting a method , extracting a class , and others, breaks your unit tests. This is a sympton of fragile tests . However, when you change behaviour or business rules, broken tests are expected. Nevertheless, your tests should not break when you change a variable from Integer to Double . Builder Pattern To The Rescue A way to avoid getting broken tests every time is to keep your unit tests as high level as possible, trying to keep it as disconnected as possible from its implementation. Here is an example of fragile test: public class AccountTest { @Test public void shouldCorrectlyDebitAValue () { final Account account = new Account ( 1L , new BigDecimal ( 10 )); final Account updatedAccount = account . debit ( new BigDecimal ( 3 )); assertThat ( updatedAccount . getTotal (), is ( new BigDecimal ( 7 ))); } } As you can see, there are many details in this code: an account has a Long value, to create it you use a constructor, passing its arguments in the given order. If you change any of these, your tests will break. However, you just want to document Whenever an account debit an amount, it returns the account with updated total. You don\u2019t care about how an account is created, what are its internals. You just want an account with some cash in it, you want to subtract and then check that it correctly calculates the debit. Using the Builder Pattern , we can avoid all this: import static com.github.vrcca.domain.account.AccountTestBuilder.anAccount ; public class AccountTest { @Test public void shouldCorrectlyDebitAValue () { final Account account = anAccount (). withTotal ( 10 ). build (); final Account updatedAccount = account . debit ( new BigDecimal ( 3 )); assertThat ( updatedAccount . getTotal (), is ( new BigDecimal ( 7 ))); } } As you can see, there is no detail on how an Account is created. Just pure high level data. You don\u2019t need to define parameters, no need to think about ordering, types. Just plain data. If we ever change the way an Account is created, we don\u2019t have to change all the tests. All we have to do is to fix our AccountTestBuilder . All tests should continue to pass. public class AccountTestBuilder { private final Integer id ; private final BigDecimal total ; public AccountTestBuilder ( Integer id , BigDecimal total ) { this . id = id ; this . total = total ; } public Account build () { return new Account ( id , total ); } // generates a valid, default account public static AccountTestBuilder anAccount () { return new AccountTestBuilder ( 1 , BigDecimal . TEN ); } public AccountTestBuilder withId ( Integer id ) { return new AccountTestBuilder ( id , total ); } public AccountTestBuilder withTotal ( BigDecimal total ) { return new AccountTestBuilder ( this . id , total ); } // helper method public AccountTestBuilder withTotal ( Integer total ) { return withTotal ( new BigDecimal ( total )); } } To sum up, keep your tests as abstract as possible. Make use of the builder pattern and create functions to help you on that.", "tags": "java tdd test", "title": "Writing Better Tests In Java - Atomic Reference"}, {"url": "https://blog.vitor.info/post/row-level-security-with-postgres-in-elixir-part-1/", "text": "This is a dump from my recent experience implementing Row-level security in Elixir and Postgres for dynamically defined tenants. What\u2019s row-level security? We need Row-level security (or just RLS) when we want certain users of the app to only see certain rows of the database. A good example is a user that, once logged in a banking app, can only see their transactions instead of the other users. How? The Ecto way There are a few ways of doing that like checking for a user_id (a.k.a tenant identifier, or tenant id) in the query or before any changes to a row, you check if that row belongs to that user. However that requires developers to always remember that any database access has this check or query filter, which is prone to human error. Repo. all ( from ( transaction in Transaction , where : transaction .user_id == current_user .id)) If we forget the where above, we\u2019ll let any user see transactions from all other users! Now imagine doing this for every DB operation. For updating and deleting data you also need to filter it: Repo . update_all(from(transaction in Transaction , where : transaction . user_id == current_user . id), set : [ status : :active ]) Or if you need to update one transaction: transaction = Repo . get( Transaction , 123 ) # or get_by(id: 123, user_id: ...) if transaction . user_id == current_user . id do # update! else { :error , :forbidden } end This pattern repeats all over the place. The Postgres way Instead of manually typing filters for every operation, we can create policies and let Postgres do that work for us. So we can run only this: Repo . all(from(transaction in Transaction )) Postgres took care of the rest! The example I\u2019d like to explain how to do the Postgres way by changing an existing app, so let\u2019s add row-level security to Chris McCord\u2019s TodoTrek . It currently relies on the tenant_id checks, but we\u2019ll make it work with Postgres RLS instead! Running the app Let\u2019s start by cloning the repo : git clone git@github.com:chrismccord/todo_trek.git If any of the examples below fails, the latest commit for me was 4d7357428993ce46625e1d39cb0fda9c0a832fc6 . The versions I used: $ mise current\nerlang 26.2.1\nelixir 1.16.0-otp-26 Start Postgres I am going to use Docker in this example, but you can use it however you want, as long as you set a superuser credential in the config/dev.exs because I will be assuming so: docker run --name todotrek -d -p 5432:5432 -e POSTGRES_PASSWORD=postgres postgres TodoTrek locally runs with a Postgres user that has superuser powers, postgres , I\u2019ll keep it like that because we are retrofitting an app, which in my experience was the most common scenario I found since startups wouldn\u2019t bother about RLS before getting enough traction and real moneys. Pull dependencies & build Run: mix setup If we try to run mix test , we\u2019ll see about 17 errors. I\u2019ll just accept fate and rely on manual testing. Start the app Run mix phx.server , open the browser at http://localhost:4000 and get used to it! To log in, just type \u201cpassword password\u201d in the password field. Now create a new user so that we can test it manually. I created a new one with the same password above, but the email anotheruser@example.com . Also create some Todos for it. ![[_resources/new_todo_list.png]] About Postgres Policies I won\u2019t go into detail about Policies because the Postgres docs do a much better job explaining it, but, in short, this is the way you tell Postgres how to filter rows. A simple example from the docs -- first enable the RLS for that table ALTER TABLE users ENABLE ROW LEVEL SECURITY ; -- create the policy CREATE POLICY user_policy ON users USING (user_name = current_user ); After running this, from now on, any queries to the users table should add the user_name filter, and this filter can be any SQL query that returns a boolean. Looks pretty simple! But there a few catches I couldn\u2019t figure out yet. Maybe there is a really obvious way to solve these, but here are a few things that got me: Catch 1: Dynamic Tenant ID I have no idea how to switch the current_user above dynamically. From the examples I found, they usually run CREATE USER #{tenant} for each tenant on sign up, but I couldn\u2019t find a simple way to switch the current_user in Ecto. So, instead I had to rely on setting local configuration parameters and fetching it in the policies with the current_setting function and it worked good enough. The example above would be translated to look like this: CREATE POLICY user_policy ON users USING (user_name = current_setting( 'app.current_user_id' )); Catch 2: SESSION and LOCAL Configurations and roles can be set at session and local level. We need to set this every time the code accesses the database, and we cannot set it at the session level or database level because otherwise we would have concurrency problems, resulting in users seeing data from other users. So this setting needs to be set within a Postgres transaction: BEGIN ; SET app.current_user_id = 123 ; SELECT * FROM users; END ; Catch 3: Bypassing RLS While learning about all this, I couldn\u2019t make this work! I created the policies, I set the local parameter, but it wouldn\u2019t filter the query results. I lost so many hours because I didn\u2019t know that superusers and table owners completely bypass RLS : Superusers and roles with the BYPASSRLS attribute always bypass the row security system when accessing a table. Table owners normally bypass row security as well, though a table owner can choose to be subject to row security with ALTER TABLE \u2026 FORCE ROW LEVEL SECURITY . To fix this, there are some options, but in my case (and for the example of this blog), I decided to keep the postgres Superuser and create a new DB user which I could switch to in runtime before running the DB operation: -- first create a new user/role that does not bypassrls: CREATE USER restricted_user NOBYPASSRLS; -- then before queries use it: SET LOCAL ROLE restricted_user; With this I was able to keep connecting with superuser, and then the query filtered correctly! The Migration plan Given the above, we\u2019ll need some DB migrations like this: CREATE USER restricted_user NOBYPASSRLS; ALTER TABLE users ENABLE ROW LEVEL SECURITY ; -- I didn't mention, but the new user needs access to the table: GRANT ALL ON users TO restricted_user; CREATE POLICY user_policy ON users TO restricted_user -- I only set it for this user USING (user_name = current_setting( 'app.current_user_id' )); Then our code will run all queries like this: BEGIN ; SET LOCAL ROLE restricted_user; SET app.current_user_id = 123 ; SELECT * FROM users; END ; Breaking the app Let\u2019s break the app. Go to lib/todo_trek/todos.ex , find the active_lists/2 function and delete all filters using the scope variable. We don\u2019t want to bother about this filter at all! Like this: def active_lists(% Scope {} = scope, limit) do from(l in List , #     where: l.user_id == &#94;scope.current_user.id, limit : &#94; limit, order_by : [ asc : :position ]\n    ) |> Repo . all() |> Repo . preload( todos :\n        from(t in Todo , #         where: t.user_id == &#94;scope.current_user.id, limit : @max_todos , order_by : [ asc : t . position]\n        )\n    ) end If you refresh the browser, you should be able to see the lists from all users. Kaboom!\n![[_resources/app_with_broken_rls.png]] Not my list. Fixing the app with Postgres RLS Alright! Let\u2019s create the migrations I mentioned, then fix this with RLS! Create the RLS user mix ecto.gen.migration create_restricted_user Open the generated file, and let\u2019s just follow the example from the Migration plan: # priv/repo/migrations/20240120163737_create_restricted_user.exs defmodule TodoTrek.Repo.Migrations.CreateRestrictedUser do use Ecto.Migration def up do execute( \"CREATE USER restricted_user NOBYPASSRLS\" ) # DO NOT RUN THIS IN PRODUCTION! GRANT ONLY WHAT IS NEEDED! # grants all powers on all tables execute( \"\"\" GRANT ALL ON ALL TABLES IN SCHEMA public TO restricted_user; \"\"\" ) # DO NOT RUN THIS IN PRODUCTION! # This grants all on future tables execute( \"\"\" ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO restricted_user; \"\"\" ) end # As an exercise, implement the `down` function def down do end end [!WARNING] > DO NOT USE THIS IN PRODUCTION! Reach out to your DB expert about the grants and default privileges ! Do not use this blindly in production! Privilege levels is out of scope of this post, so for simplicity I am granting all on everything. Create the Policy I\u2019ll do it only for the lists table and won\u2019t bother about the todos table, but we should ! Feel free to do it as an exercise. mix ecto.gen.migration create_rls_policy_for_lists Open the generated file, and let\u2019s just follow the example from the Migration plan again: # priv/repo/migrations/20240120164315_create_rls_policy_for_lists.exs defmodule TodoTrek.Repo.Migrations.CreateRlsPolicyForLists do use Ecto.Migration def up do execute( \"ALTER TABLE lists ENABLE ROW LEVEL SECURITY;\" )\n\n    execute( \"\"\" CREATE POLICY list_policy ON lists TO restricted_user USING (user_id = current_setting('app.current_user_id')::bigint); \"\"\" ) end def down do # exercise end end See that ::bigint in there? That\u2019s necessary because the user_id is an integer, but the current_setting returns text . It needs conversion! RLS in action! Run mix ecto.migrate , and let\u2019s see it in action in IEX! iex -S mix phx.server Without RLS Assuming that you created more account with Todos, running this should return all lists from all users: iex > lists = TodoTrek.Todos . active_lists(% TodoTrek.Scope {}, 10 )\niex > Enum . map(lists, & &1 . user_id) |> Enum . uniq()\n[ 1 , 2 ] Oops! We need to set the app.current_user_id and restricted_user ! With RLS It doesn\u2019t look nice, but stay with me: iex > alias TodoTrek.Repo iex > { :ok , lists} = Repo . transaction( fn -> iex > Repo . query!( \"SET LOCAL ROLE restricted_user;\" )\niex > Repo . query!( \"SET app.current_user_id = '1';\" )\niex > TodoTrek.Todos . active_lists(% TodoTrek.Scope {}, 20 )\niex > end )\n...\niex > Enum . map(lists, & &1 . user_id) |> Enum . uniq()\n[ 1 ] It works! Try again without the SET LOCAL ROLE restricted_user and see what happens. It should return all anyway because it runs the query with the superuser which bypasses RLS. Replace the function Let\u2019s move all this to active_lists/2 def active_lists(% Scope {} = scope, limit) do { :ok , lists} = Repo . transaction( fn -> Repo . query!( \"SET LOCAL ROLE restricted_user;\" ) Repo . query!( \"SET app.current_user_id = ' #{ scope . current_user . id } ';\" )\n\n        from(l in List , limit : &#94; limit, order_by : [ asc : :position ]\n        ) |> Repo . all() |> Repo . preload( todos :\n            from(t in Todo , limit : @max_todos , order_by : [ asc : t . position]\n            )\n        ) end )\n\n    lists end Refreshing the page should get you back to the initial and correct state. But this code looks so ugly, and repeating this everywhere wouldn\u2019t be fun. I honestly wouldn\u2019t want to imagine the reviews on this code! We need to find a way to wrap all DB calls with the transaction above, then everything will be automatically filtered by Postgres. I want the function to look like this and get rid of the scope argument: def active_lists(limit) do from(l in List , limit : &#94; limit, order_by : [ asc : :position ]\n    ) |> Repo . all() |> Repo . preload( todos :\n        from(t in Todo , limit : @max_todos , order_by : [ asc : t . position]\n        )\n    ) end Next steps On the next post I will continue working on the example above. I should a few ways I learned to wrap all DB calls in a transaction that sets the local role and current_user_id parameter. We\u2019ll learn about Process dictionary and wrapping the TodoTrek.Repo functions!", "tags": "elixir postgres blog", "title": "Row-level Security with Postgres in Elixir - Atomic Reference"}, {"url": "https://blog.vitor.info/post/my-first-post/", "text": "Hello world! Here is my first post. I shall begin it explaining how I setup this blog using GitHub Pages, GitLab and Hugo. Creating a new GitHub Pages To setup a new GitHub page, the website tutorial is pretty straightforward, so I will skip this. Hugo Hugo is a static website generator built on Go. It is extremely fast and requires little setup to start using it. To install it is as simple as: MacOS brew install hugo Linux apt install hugo or snap install hugo Hugo has many themes you can choose. For this post I will use Pixyll which is the same I used for this blog. It has support to Google Analytics, Markdown and Disqus integration, which is something I was looking for. Up and running After installing Hugo, you can create a new site with: $ hugo new site my-new-blog And you can start a server with: $ hugo server This will build all static files and keep an eye on any updates you do in your posts. To create a new post just type: $ hugo new post file-name Installing a theme You can follow the instructions of the theme, but usually it goes like this: $ cd my-new-blog\n$ git clone https://github.com/azmelanar/hugo-theme-pixyll.git themes/hugo-theme-pixyll\n\n# Copies default configurations from themes to your new site\n$ cp -R themes/hugo-theme-pixyll/exampleSite/config.toml ./config.toml After that, it\u2019s important for you to edit the file config.toml and properly set your name, baseUrl, GitHub page, etc. You can run hugo server to make sure that it works properly. Manually deploying your changes to GitHub pages After creating your GitHub Pages, clone it in the parent directory that has your new hugo website. Then you will have to copy all static files from your hugo website to the GitHub pages repository, commit and push the changes. You can manually deploy your new blog with the following commands: # Generates the static files required by GitHub pages\n$ hugo -d ../my-new-blog.github.io/\n$ cd ../my-new-blog.github.io/\n$ git commit -am \"My new blog\"\n$ git push If you try to access your GitHub pages, you should see it working as it would locally. Automatically building & deploying from GitLab If you are like me, you probably don\u2019t want to remember to type the commands above for each post. So I researched how to automatically generate a new blog version automatically, but the solution ends up either creating a deploy.sh script to manually run it or use CI. We are going to do the latter with GitLab CI . Why GitLab? It has free private repositories; CI/CD built-in; Kanban boards; WebIDE (you can create your blog posts in your browser. No need to install hugo.) Free private groups; and more! Let\u2019s start by creating our GitLab repository first: Create a new user account in GitLab for free. Create a new project with whatever name you like. Here I made my repository private, but it is up to you to decide. Clone the repository locally and push the files from your hugo setup. Now we need to tell GitLab to install Hugo, build our static files and deploy them to GitHub (just like we would do manually). Like I said before, we are going to use GitLab CI.\nTo setup GitLab CI it\u2019s pretty simple, just add a file named .gitlab-ci.yml to the root of your GitLab project, and it should start building. This file is used to tell GitLab how to build your repository. The steps we need to reproduce in GitLab basically are install, build and deploy: Somehow install Hugo somewhere; With the files from our GitLab repository, automatically build our blog; Deploy the generated files to GitHub; Our build will have two phases: build and deploy. So add this to the top of your .gitlab-ci.yml : stages:\n  - build\n  - deploy The stages property is used so you can make GitLab follow the given order when running your build steps. In this case, it will run all the steps that has build set to stage property, then deploy . Installing Hugo in GitLab CI All builds in GitLab run within a docker container, therefore, if your container run linux, you can run any Linux command in it. You can install Hugo and build your blog by adding this to our .gitlab-ci.yml : build:\n  stage: build\n  before_script:\n    - curl -L -o hugo.deb https://github.com/gohugoio/hugo/releases/download/v0.49.2/hugo_0.49.2_Linux-64bit.deb\n    - dpkg -i hugo.deb\n  script:\n    - mkdir -p build/ && hugo -d build/\n  artifacts:\n    name: 'blog-$CI_COMMIT_REF_NAME'\n    expire_in: 1 day\n    paths:\n      - build/ The artifacts step tells GitLab that, after this whole step finishes, you want to keep the build/ folder for a single day. This is useful in case you want to rollback changes or debug what your CI is doing. Automatically Deploying to GitHub Pages Now that we have installed Hugo and generated our static website, we need to deploy to GitHub. Deploying to GitHub requires us to clone our git repository from GitHub, copy our new build to it, and commit and pushing the changes. deploy:\n  stage: deploy\n  before_script:\n    - git clone https://githubusername:$GITHUB_ACCESS_TOKEN@github.com/githubusername/newblog.github.io.git blog-github/\n    - git config --global user.name \"AuthorName\"\n    - git config --global user.email \"email@myemail.com\"\n  script:\n    - rm -rf blog-github/content/\n    - cp -R build/* blog-github/\n    - cd blog-github/\n    - git diff --quiet && git diff --staged --quiet || git commit -am \"$CI_COMMIT_TITLE\" && git push\n  dependencies:\n    - build The before_script clones your repository with an user and password. The $GITHUB_ACCESS_TOKEN variable could be replaced with your GitHub\u2019s password, but we don\u2019t want to expose that. We will revisit it later. It also sets your name and email for future commits. The scripts steps does this: Removes the content/ folder. This is needed because you would never be able to rename or remove a post otherwise. Copies all static content from the build/ folder generated in the the previous step (see dependencies property) to the GitHub directory. The fourth step only adds and commits files if there are any changes in your git diff command. That\u2019s why we run a command with || . If there is no diff, there is no need to push things. The dependencies property tells GitLab that this step has dependencies with the build step. This enables us to reference files generated in other builds and maps a dependency graph between steps. After adding all this to .gitlab-ci.yml and commiting to GitLab, the build should be broken, but you should see that the CI/CD Pipelines are now being triggered on changes. We still need to set the $GITHUB_ACCESS_TOKEN variable. Defining GitLab CI Environment Variables We don\u2019t want to expose our passwords in files, because other people could have access to it. If you are the only person that will ever have access to this repository, then you can ignore all this and just replace the variable in your configuration file. However, it is STRONGLY advised to keep your secrets somewhere safe. Steps You can skip the steps below and go right to the page to create a token here . In your GitHub, go to Settings On the left bottom, click Developer Settings Then Personal access tokens Click on Generate new token Select public_repo Finally, Click Generate token With your new token, go to your repository in GitLab. Click on Settings Then CI / CD Expand the Variables section. For variable name, type GITHUB_ACCESS_TOKEN For the value, enter the new token. Mark it as Protected Save variables If you try to run your pipeline now, it should pass correctly. You should also see that your changes are now being pushed to your GitHub pages and that your website is now being correctly displayed. I hope this helps! Thanks for reading my first post!", "tags": "blog gitlab hugo", "title": "Hello World! - Atomic Reference"}, {"url": "https://blog.vitor.info/post/getting-the-current-page-in-phoenix/", "text": "When programming in Phoenix Framework , you sometimes need to code a decision point based on the current page. To do this, we can make use of Plug.Conn\u2019s path_info field and compare it with Routes . Let\u2019s say you have the following piece of code: < % = if is_accounts_page( @conn ) % > < div > # Account related content </ div > < % end % > To find out if the user is in the account route, you can compare the current path with the Account page route in LayoutView : def is_accounts_page(conn = % Plug.Conn { path_info : path_info}) do path_info |> join_path() |> String . equivalent?( Routes . accounts_path(conn, :index )) end defp join_path(path_info), do : \"/\" <> Enum . join(path_info, \"/\" ) As we can see, in the first line we extract the path_info from conn . Then we join all path parts into a single string. Finally, we compare the current path with the Routes.accounts_path . You can go even further and make this function work for any page by passing the route path as argument. I hope it helps. Please, let me know what you thought about this approach.", "tags": "elixir phoenix phoenixframework", "title": "Getting The Current Page in Phoenix Framework - Atomic Reference"}]};